{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd506ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample transaction data\n",
    "def generate_transaction_data(n_transactions=10000):\n",
    "    \"\"\"\n",
    "    Generate synthetic transaction data with fraud indicators\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for i in range(n_transactions):\n",
    "        # Basic transaction info\n",
    "        transaction_id = f\"TXN_{i+1:06d}\"\n",
    "        \n",
    "        # Amount - fraudulent transactions tend to be higher or very low\n",
    "        if np.random.random() < 0.05:  # 5% fraud rate\n",
    "            is_fraud = 1\n",
    "            if np.random.random() < 0.7:\n",
    "                amount = np.random.exponential(2000)  # Higher amounts\n",
    "            else:\n",
    "                amount = np.random.uniform(1, 10)  # Very low amounts\n",
    "        else:\n",
    "            is_fraud = 0\n",
    "            amount = np.random.exponential(150)  # Normal amounts\n",
    "        \n",
    "        # Time of day (0-23 hours)\n",
    "        if is_fraud:\n",
    "            # Fraudulent transactions more likely at odd hours\n",
    "            hour = np.random.choice([0,1,2,3,22,23], p=[0.2,0.2,0.2,0.2,0.1,0.1]) if np.random.random() < 0.6 else np.random.randint(0, 24)\n",
    "        else:\n",
    "            # Normal transactions during business hours\n",
    "            hour = np.random.choice(range(8, 20)) if np.random.random() < 0.7 else np.random.randint(0, 24)\n",
    "        \n",
    "        # Device type\n",
    "        device_types = ['mobile', 'desktop', 'tablet']\n",
    "        if is_fraud:\n",
    "            device = np.random.choice(device_types, p=[0.6, 0.3, 0.1])  # Fraudsters prefer mobile\n",
    "        else:\n",
    "            device = np.random.choice(device_types, p=[0.4, 0.5, 0.1])  # Normal distribution\n",
    "        \n",
    "        # Location risk (1-10 scale)\n",
    "        if is_fraud:\n",
    "            location_risk = np.random.randint(6, 11)  # Higher risk locations\n",
    "        else:\n",
    "            location_risk = np.random.randint(1, 6)   # Lower risk locations\n",
    "        \n",
    "        # Account age (days)\n",
    "        if is_fraud:\n",
    "            account_age = np.random.randint(1, 30)    # New accounts more risky\n",
    "        else:\n",
    "            account_age = np.random.randint(30, 1000) # Established accounts\n",
    "        \n",
    "        # Previous transaction count in last 24h\n",
    "        if is_fraud:\n",
    "            prev_transactions = np.random.randint(0, 3)  # Fewer previous transactions\n",
    "        else:\n",
    "            prev_transactions = np.random.randint(1, 10) # Normal activity\n",
    "        \n",
    "        data.append({\n",
    "            'transaction_id': transaction_id,\n",
    "            'amount': round(amount, 2),\n",
    "            'hour': hour,\n",
    "            'device': device,\n",
    "            'location_risk': location_risk,\n",
    "            'account_age': account_age,\n",
    "            'prev_transactions_24h': prev_transactions,\n",
    "            'is_fraud': is_fraud\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate the dataset\n",
    "df = generate_transaction_data(10000)\n",
    "print(\"Dataset created successfully!\")\n",
    "print(f\"Total transactions: {len(df)}\")\n",
    "print(f\"Fraud transactions: {df['is_fraud'].sum()}\")\n",
    "print(f\"Fraud rate: {df['is_fraud'].mean():.2%}\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nFraud Distribution by Device:\")\n",
    "print(pd.crosstab(df['device'], df['is_fraud'], normalize='columns'))\n",
    "\n",
    "# Create feature engineering function\n",
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Prepare features for the logistic regression model\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # One-hot encode device type\n",
    "    device_dummies = pd.get_dummies(df_processed['device'], prefix='device')\n",
    "    df_processed = pd.concat([df_processed, device_dummies], axis=1)\n",
    "    \n",
    "    # Create time-based features\n",
    "    df_processed['is_night'] = (df_processed['hour'] < 6) | (df_processed['hour'] > 22)\n",
    "    df_processed['is_business_hours'] = (df_processed['hour'] >= 9) & (df_processed['hour'] <= 17)\n",
    "    \n",
    "    # Create amount-based features\n",
    "    df_processed['log_amount'] = np.log1p(df_processed['amount'])\n",
    "    df_processed['high_amount'] = df_processed['amount'] > df_processed['amount'].quantile(0.95)\n",
    "    df_processed['low_amount'] = df_processed['amount'] < 10\n",
    "    \n",
    "    # Create account risk features\n",
    "    df_processed['new_account'] = df_processed['account_age'] < 30\n",
    "    df_processed['low_activity'] = df_processed['prev_transactions_24h'] < 2\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Prepare features\n",
    "df_features = prepare_features(df)\n",
    "print(\"Features prepared successfully!\")\n",
    "print(f\"Number of features: {df_features.shape[1]}\")\n",
    "\n",
    "# Select features for modeling\n",
    "feature_columns = [\n",
    "    'amount', 'log_amount', 'hour', 'location_risk', 'account_age', \n",
    "    'prev_transactions_24h', 'device_desktop', 'device_mobile', \n",
    "    'device_tablet', 'is_night', 'is_business_hours', 'high_amount', \n",
    "    'low_amount', 'new_account', 'low_activity'\n",
    "]\n",
    "\n",
    "X = df_features[feature_columns]\n",
    "y = df_features['is_fraud']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Training accuracy: {model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"Test accuracy: {model.score(X_test_scaled, y_test):.3f}\")\n",
    "\n",
    "def score_transaction(transaction_data, model, scaler, feature_columns):\n",
    "    \"\"\"\n",
    "    Score a single transaction or batch of transactions for fraud probability\n",
    "    \n",
    "    Parameters:\n",
    "    - transaction_data: dict or DataFrame with transaction details\n",
    "    - model: trained logistic regression model\n",
    "    - scaler: fitted StandardScaler\n",
    "    - feature_columns: list of feature column names\n",
    "    \n",
    "    Returns:\n",
    "    - fraud_probability: probability of fraud (0-1)\n",
    "    - risk_category: 'Safe', 'Suspicious', or 'Likely Fraud'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert single transaction to DataFrame if needed\n",
    "    if isinstance(transaction_data, dict):\n",
    "        df_single = pd.DataFrame([transaction_data])\n",
    "    else:\n",
    "        df_single = transaction_data.copy()\n",
    "    \n",
    "    # Prepare features\n",
    "    df_processed = prepare_features(df_single)\n",
    "    \n",
    "    # Select and scale features\n",
    "    X_score = df_processed[feature_columns]\n",
    "    X_score_scaled = scaler.transform(X_score)\n",
    "    \n",
    "    # Get fraud probabilities\n",
    "    fraud_probabilities = model.predict_proba(X_score_scaled)[:, 1]\n",
    "    \n",
    "    # Classify risk levels\n",
    "    risk_categories = []\n",
    "    for prob in fraud_probabilities:\n",
    "        if prob < 0.3:\n",
    "            risk_categories.append('Safe')\n",
    "        elif prob < 0.7:\n",
    "            risk_categories.append('Suspicious')\n",
    "        else:\n",
    "            risk_categories.append('Likely Fraud')\n",
    "    \n",
    "    if len(fraud_probabilities) == 1:\n",
    "        return fraud_probabilities[0], risk_categories[0]\n",
    "    else:\n",
    "        return fraud_probabilities, risk_categories\n",
    "\n",
    "# Test the scoring function with a sample transaction\n",
    "sample_transaction = {\n",
    "    'amount': 2500.00,\n",
    "    'hour': 2,\n",
    "    'device': 'mobile',\n",
    "    'location_risk': 8,\n",
    "    'account_age': 5,\n",
    "    'prev_transactions_24h': 1\n",
    "}\n",
    "\n",
    "fraud_prob, risk_category = score_transaction(sample_transaction, model, scaler, feature_columns)\n",
    "print(f\"Sample Transaction Scoring:\")\n",
    "print(f\"Fraud Probability: {fraud_prob:.3f}\")\n",
    "print(f\"Risk Category: {risk_category}\")\n",
    "\n",
    "# Score all transactions in the test set\n",
    "fraud_probs, risk_categories = score_transaction(df_features.iloc[X_test.index], model, scaler, feature_columns)\n",
    "\n",
    "# Add results to test dataframe\n",
    "test_results = df_features.iloc[X_test.index].copy()\n",
    "test_results['fraud_probability'] = fraud_probs\n",
    "test_results['predicted_risk'] = risk_categories\n",
    "test_results['actual_fraud'] = test_results['is_fraud'].map({0: 'Not Fraud', 1: 'Fraud'})\n",
    "\n",
    "print(\"All transactions scored successfully!\")\n",
    "print(f\"Transactions processed: {len(test_results)}\")\n",
    "\n",
    "# Risk category distribution\n",
    "print(\"Risk Category Distribution:\")\n",
    "risk_dist = test_results['predicted_risk'].value_counts()\n",
    "print(risk_dist)\n",
    "print(f\"\\nPercentages:\")\n",
    "print((risk_dist / len(test_results) * 100).round(2))\n",
    "\n",
    "# Cross-tabulation of predicted vs actual\n",
    "print(\"\\nPredicted Risk vs Actual Fraud:\")\n",
    "confusion_table = pd.crosstab(test_results['predicted_risk'], test_results['actual_fraud'])\n",
    "print(confusion_table)\n",
    "\n",
    "# Calculate precision for each risk category\n",
    "print(\"\\nPrecision by Risk Category:\")\n",
    "for category in ['Safe', 'Suspicious', 'Likely Fraud']:\n",
    "    subset = test_results[test_results['predicted_risk'] == category]\n",
    "    if len(subset) > 0:\n",
    "        precision = subset['is_fraud'].mean()\n",
    "        print(f\"{category}: {precision:.3f} ({precision:.1%})\")\n",
    "\n",
    "# Create detailed report for high-risk transactions\n",
    "high_risk_transactions = test_results[test_results['predicted_risk'].isin(['Suspicious', 'Likely Fraud'])].copy()\n",
    "high_risk_transactions = high_risk_transactions.sort_values('fraud_probability', ascending=False)\n",
    "\n",
    "print(\"HIGH RISK TRANSACTIONS REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total high-risk transactions: {len(high_risk_transactions)}\")\n",
    "print(f\"Likely Fraud: {(high_risk_transactions['predicted_risk'] == 'Likely Fraud').sum()}\")\n",
    "print(f\"Suspicious: {(high_risk_transactions['predicted_risk'] == 'Suspicious').sum()}\")\n",
    "\n",
    "# Display top 10 highest risk transactions\n",
    "print(\"\\nTop 10 Highest Risk Transactions:\")\n",
    "display_columns = ['transaction_id', 'amount', 'hour', 'device', 'location_risk', \n",
    "                  'account_age', 'fraud_probability', 'predicted_risk', 'actual_fraud']\n",
    "print(high_risk_transactions[display_columns].head(10).to_string(index=False))\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Fraud Probability Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Histogram of fraud probabilities\n",
    "axes[0, 0].hist(test_results[test_results['is_fraud'] == 0]['fraud_probability'], \n",
    "                bins=50, alpha=0.7, label='Not Fraud', color='green', density=True)\n",
    "axes[0, 0].hist(test_results[test_results['is_fraud'] == 1]['fraud_probability'], \n",
    "                bins=50, alpha=0.7, label='Fraud', color='red', density=True)\n",
    "axes[0, 0].set_xlabel('Fraud Probability')\n",
    "axes[0, 0].set_ylabel('Density')\n",
    "axes[0, 0].set_title('Distribution of Fraud Probabilities')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box plot by risk category\n",
    "risk_order = ['Safe', 'Suspicious', 'Likely Fraud']\n",
    "box_data = [test_results[test_results['predicted_risk'] == cat]['fraud_probability'] \n",
    "            for cat in risk_order]\n",
    "bp = axes[0, 1].boxplot(box_data, labels=risk_order, patch_artist=True)\n",
    "colors = ['green', 'orange', 'red']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[0, 1].set_ylabel('Fraud Probability')\n",
    "axes[0, 1].set_title('Fraud Probability by Risk Category')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. ROC-like curve showing probability thresholds\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "true_positive_rates = []\n",
    "false_positive_rates = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    predictions = (test_results['fraud_probability'] >= threshold).astype(int)\n",
    "    tp = ((predictions == 1) & (test_results['is_fraud'] == 1)).sum()\n",
    "    fp = ((predictions == 1) & (test_results['is_fraud'] == 0)).sum()\n",
    "    tn = ((predictions == 0) & (test_results['is_fraud'] == 0)).sum()\n",
    "    fn = ((predictions == 0) & (test_results['is_fraud'] == 1)).sum()\n",
    "    \n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    true_positive_rates.append(tpr)\n",
    "    false_positive_rates.append(fpr)\n",
    "\n",
    "axes[1, 0].plot(false_positive_rates, true_positive_rates, 'b-', linewidth=2)\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('False Positive Rate')\n",
    "axes[1, 0].set_ylabel('True Positive Rate')\n",
    "axes[1, 0].set_title('ROC Curve')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': abs(model.coef_[0])\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[1, 1].barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "axes[1, 1].set_yticks(range(len(feature_importance)))\n",
    "axes[1, 1].set_yticklabels(feature_importance['feature'])\n",
    "axes[1, 1].set_xlabel('Absolute Coefficient Value')\n",
    "axes[1, 1].set_title('Feature Importance')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/fraud_analysis_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create risk category analysis plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Risk Category Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Risk category counts\n",
    "risk_counts = test_results['predicted_risk'].value_counts()\n",
    "colors = ['green', 'orange', 'red']\n",
    "axes[0, 0].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', \n",
    "               colors=colors, startangle=90)\n",
    "axes[0, 0].set_title('Distribution of Risk Categories')\n",
    "\n",
    "# 2. Fraud rate by risk category\n",
    "fraud_rates = test_results.groupby('predicted_risk')['is_fraud'].mean()\n",
    "bars = axes[0, 1].bar(fraud_rates.index, fraud_rates.values, color=colors)\n",
    "axes[0, 1].set_ylabel('Fraud Rate')\n",
    "axes[0, 1].set_title('Actual Fraud Rate by Predicted Risk Category')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "for bar, rate in zip(bars, fraud_rates.values):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{rate:.1%}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Amount distribution by risk category\n",
    "for i, category in enumerate(['Safe', 'Suspicious', 'Likely Fraud']):\n",
    "    data = test_results[test_results['predicted_risk'] == category]['amount']\n",
    "    axes[1, 0].hist(data, bins=30, alpha=0.7, label=category, color=colors[i])\n",
    "axes[1, 0].set_xlabel('Transaction Amount ($)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Transaction Amount Distribution by Risk Category')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_xlim(0, 1000)  # Focus on typical amounts\n",
    "\n",
    "# 4. Time of day analysis\n",
    "hour_risk = test_results.groupby('hour')['fraud_probability'].mean()\n",
    "axes[1, 1].plot(hour_risk.index, hour_risk.values, 'bo-', linewidth=2, markersize=6)\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Average Fraud Probability')\n",
    "axes[1, 1].set_title('Fraud Risk by Time of Day')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_xticks(range(0, 24, 4))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/risk_category_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate comprehensive performance metrics\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Binary predictions using 0.5 threshold\n",
    "y_pred_binary = (test_results['fraud_probability'] >= 0.5).astype(int)\n",
    "\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_results['is_fraud'], y_pred_binary))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(test_results['is_fraud'], y_pred_binary)\n",
    "print(cm)\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(test_results['is_fraud'], \n",
    "                                                      test_results['fraud_probability'])\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(f\"\\nPrecision-Recall AUC: {pr_auc:.3f}\")\n",
    "\n",
    "# Business impact analysis\n",
    "total_transactions = len(test_results)\n",
    "flagged_transactions = (test_results['predicted_risk'] != 'Safe').sum()\n",
    "actual_fraud_caught = test_results[(test_results['predicted_risk'] != 'Safe') & \n",
    "                                  (test_results['is_fraud'] == 1)].shape[0]\n",
    "total_fraud = test_results['is_fraud'].sum()\n",
    "\n",
    "print(f\"\\nBUSINESS IMPACT ANALYSIS\")\n",
    "print(f\"Total transactions analyzed: {total_transactions:,}\")\n",
    "print(f\"Transactions flagged for review: {flagged_transactions:,} ({flagged_transactions/total_transactions:.1%})\")\n",
    "print(f\"Actual fraud cases caught: {actual_fraud_caught}/{total_fraud} ({actual_fraud_caught/total_fraud:.1%})\")\n",
    "print(f\"Review efficiency: {actual_fraud_caught/flagged_transactions:.1%} fraud rate in flagged transactions\")\n",
    "\n",
    "class FraudDetectionSystem:\n",
    "    \"\"\"\n",
    "    Production-ready fraud detection system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, scaler, feature_columns):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.feature_columns = feature_columns\n",
    "        self.transaction_log = []\n",
    "    \n",
    "    def score_transaction(self, transaction):\n",
    "        \"\"\"\n",
    "        Score a single transaction and return detailed results\n",
    "        \"\"\"\n",
    "        # Prepare transaction data\n",
    "        df_single = pd.DataFrame([transaction])\n",
    "        df_processed = prepare_features(df_single)\n",
    "        \n",
    "        # Score transaction\n",
    "        X_score = df_processed[self.feature_columns]\n",
    "        X_score_scaled = self.scaler.transform(X_score)\n",
    "        fraud_prob = self.model.predict_proba(X_score_scaled)[0, 1]\n",
    "        \n",
    "        # Determine risk category and action\n",
    "        if fraud_prob < 0.3:\n",
    "            risk_category = 'Safe'\n",
    "            action = 'Approve'\n",
    "        elif fraud_prob < 0.7:\n",
    "            risk_category = 'Suspicious'\n",
    "            action = 'Manual Review'\n",
    "        else:\n",
    "            risk_category = 'Likely Fraud'\n",
    "            action = 'Decline'\n",
    "        \n",
    "        # Create result\n",
    "        result = {\n",
    "            'transaction_id': transaction['transaction_id'],\n",
    "            'fraud_probability': fraud_prob,\n",
    "            'risk_category': risk_category,\n",
    "            'recommended_action': action,\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'risk_factors': self._identify_risk_factors(df_processed, fraud_prob)\n",
    "        }\n",
    "        \n",
    "        # Log transaction\n",
    "        self.transaction_log.append(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _identify_risk_factors(self, df_processed, fraud_prob):\n",
    "        \"\"\"\n",
    "        Identify key risk factors for the transaction\n",
    "        \"\"\"\n",
    "        risk_factors = []\n",
    "        \n",
    "        if df_processed['amount'].iloc[0] > 1000:\n",
    "            risk_factors.append('High transaction amount')\n",
    "        \n",
    "        if df_processed['is_night'].iloc[0]:\n",
    "            risk_factors.append('Transaction during night hours')\n",
    "        \n",
    "        if df_processed['new_account'].iloc[0]:\n",
    "            risk_factors.append('New account (< 30 days)')\n",
    "        \n",
    "        if df_processed['location_risk'].iloc[0] > 7:\n",
    "            risk_factors.append('High-risk location')\n",
    "        \n",
    "        if df_processed['low_activity'].iloc[0]:\n",
    "            risk_factors.append('Low recent account activity')\n",
    "        \n",
    "        return risk_factors\n",
    "    \n",
    "    def batch_score(self, transactions):\n",
    "        \"\"\"\n",
    "        Score multiple transactions\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for transaction in transactions:\n",
    "            result = self.score_transaction(transaction)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def get_daily_summary(self):\n",
    "        \"\"\"\n",
    "        Generate daily fraud detection summary\n",
    "        \"\"\"\n",
    "        if not self.transaction_log:\n",
    "            return \"No transactions processed today.\"\n",
    "        \n",
    "        df_log = pd.DataFrame(self.transaction_log)\n",
    "        today_log = df_log[df_log['timestamp'].dt.date == pd.Timestamp.now().date()]\n",
    "        \n",
    "        summary = {\n",
    "            'total_transactions': len(today_log),\n",
    "            'safe_transactions': (today_log['risk_category'] == 'Safe').sum(),\n",
    "            'suspicious_transactions': (today_log['risk_category'] == 'Suspicious').sum(),\n",
    "            'likely_fraud': (today_log['risk_category'] == 'Likely Fraud').sum(),\n",
    "            'average_fraud_probability': today_log['fraud_probability'].mean(),\n",
    "            'transactions_declined': (today_log['recommended_action'] == 'Decline').sum()\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize the fraud detection system\n",
    "fraud_system = FraudDetectionSystem(model, scaler, feature_columns)\n",
    "\n",
    "print(\"Fraud Detection System initialized successfully!\")\n",
    "\n",
    "# Test transactions with different risk profiles\n",
    "test_transactions = [\n",
    "    {\n",
    "        'transaction_id': 'TEST_001',\n",
    "        'amount': 50.00,\n",
    "        'hour': 14,\n",
    "        'device': 'desktop',\n",
    "        'location_risk': 3,\n",
    "        'account_age': 365,\n",
    "        'prev_transactions_24h': 5\n",
    "    },\n",
    "    {\n",
    "        'transaction_id': 'TEST_002',\n",
    "        'amount': 2500.00,\n",
    "        'hour': 3,\n",
    "        'device': 'mobile',\n",
    "        'location_risk': 9,\n",
    "        'account_age': 2,\n",
    "        'prev_transactions_24h': 0\n",
    "    },\n",
    "    {\n",
    "        'transaction_id': 'TEST_003',\n",
    "        'amount': 150.00,\n",
    "        'hour': 10,\n",
    "        'device': 'tablet',\n",
    "        'location_risk': 5,\n",
    "        'account_age': 180,\n",
    "        'prev_transactions_24h': 3\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"TESTING FRAUD DETECTION SYSTEM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for transaction in test_transactions:\n",
    "    result = fraud_system.score_transaction(transaction)\n",
    "    \n",
    "    print(f\"\\nTransaction ID: {result['transaction_id']}\")\n",
    "    print(f\"Fraud Probability: {result['fraud_probability']:.3f}\")\n",
    "    print(f\"Risk Category: {result['risk_category']}\")\n",
    "    print(f\"Recommended Action: {result['recommended_action']}\")\n",
    "    print(f\"Risk Factors: {', '.join(result['risk_factors']) if result['risk_factors'] else 'None identified'}\")\n",
    "\n",
    "# Generate daily summary\n",
    "summary = fraud_system.get_daily_summary()\n",
    "print(f\"\\nDAILY SUMMARY:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(model, 'scripts/fraud_detection_model.pkl')\n",
    "joblib.dump(scaler, 'scripts/fraud_scaler.pkl')\n",
    "\n",
    "# Save feature columns\n",
    "with open('scripts/feature_columns.json', 'w') as f:\n",
    "    json.dump(feature_columns, f)\n",
    "\n",
    "# Save test results\n",
    "test_results.to_csv('data/fraud_analysis_results.csv', index=False)\n",
    "\n",
    "# Save high-risk transactions report\n",
    "high_risk_transactions.to_csv('data/high_risk_transactions.csv', index=False)\n",
    "\n",
    "print(\"Model and results saved successfully!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- scripts/fraud_detection_model.pkl\")\n",
    "print(\"- scripts/fraud_scaler.pkl\") \n",
    "print(\"- scripts/feature_columns.json\")\n",
    "print(\"- data/fraud_analysis_results.csv\")\n",
    "print(\"- data/high_risk_transactions.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
