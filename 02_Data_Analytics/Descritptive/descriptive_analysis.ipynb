{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d1GusWS0yXn"
      },
      "source": [
        "**Large datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Process data in chunks if memory is limited\n",
        "chunk_size = 1000\n",
        "for chunk in pd.read_csv('large_fintech_file.csv', chunksize=chunk_size):\n",
        "    # Process each chunk\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXEYtR_-_ER-"
      },
      "outputs": [],
      "source": [
        "# For large datasets, use sampling:\n",
        "fintech_df = large_fintech_df.sample(n=1000)  # Sample 1000 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Descriptive** **Analytics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Process data in chunks and sample from each chunk\n",
        "chunk_size = 1000\n",
        "chunk_samples = []\n",
        "\n",
        "for chunk in pd.read_csv('large_fintech_file.csv', chunksize=chunk_size):\n",
        "    chunk_sample = chunk.sample(n=100)  # Sample 100 rows from the chunk\n",
        "    chunk_samples.append(chunk_sample)\n",
        "\n",
        "# Combine all sampled chunks into a single DataFrame\n",
        "sampled_data = pd.concat(chunk_samples, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdshrTTl03tg"
      },
      "outputs": [],
      "source": [
        "fintech_means = fintech_df.select_dtypes(include=[np.number]).mean()\n",
        "for column, mean_value in fintech_means.items():\n",
        "    print(f\"{column}: ${mean_value:,.2f}\" if 'balance' in column or 'income' in column or 'loan' in column\n",
        "          else f\"{column}: {mean_value:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLlDRHqe2mBO"
      },
      "outputs": [],
      "source": [
        "fintech_medians = fintech_df.select_dtypes(include=[np.number]).median()\n",
        "for column, median_value in fintech_medians.items():\n",
        "    print(f\"{column}: ${median_value:,.2f}\" if 'balance' in column or 'income' in column or 'loan' in column\n",
        "          else f\"{column}: {median_value:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ-3v6bI1GZe"
      },
      "outputs": [],
      "source": [
        "for column in fintech_df.select_dtypes(include=[np.number]).columns:\n",
        "    mode_value = fintech_df[column].mode()\n",
        "    if len(mode_value) > 0:\n",
        "        print(f\"{column}: {mode_value.iloc[0]:.2f}\")\n",
        "    else:\n",
        "        print(f\"{column}: No mode found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNq6MfoE2xbP"
      },
      "outputs": [],
      "source": [
        "for column in fintech_df.select_dtypes(include=[np.number]).columns:\n",
        "    min_val = fintech_df[column].min()\n",
        "    max_val = fintech_df[column].max()\n",
        "    print(f\"{column}: Min = {min_val:.2f}, Max = {max_val:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQTcDEOt4Kx6"
      },
      "outputs": [],
      "source": [
        "fintech_std = fintech_df.select_dtypes(include=[np.number]).std()\n",
        "for column, std_value in fintech_std.items():\n",
        "    print(f\"{column}: {std_value:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrhPNRwD21PT"
      },
      "outputs": [],
      "source": [
        "quantiles = [0.25, 0.5, 0.75]\n",
        "for column in ['account_balance', 'credit_score', 'annual_income']:\n",
        "    print(f\"\\n{column}:\")\n",
        "    for q in quantiles:\n",
        "        value = fintech_df[column].quantile(q)\n",
        "        print(f\"  {int(q*100)}th percentile: {value:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAAPBmMz4XQX"
      },
      "outputs": [],
      "source": [
        "def calculate_iqr(df, column):\n",
        "    q1 = df[column].quantile(0.25)\n",
        "    q3 = df[column].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    return q1, q3, iqr\n",
        "\n",
        "print(\"\\nFintech Dataset IQR:\")\n",
        "for column in ['account_balance', 'credit_score', 'loan_amount']:\n",
        "    q1, q3, iqr = calculate_iqr(fintech_df, column)\n",
        "    print(f\"{column}: Q1={q1:.2f}, Q3={q3:.2f}, IQR={iqr:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xea6OnnW28MH"
      },
      "outputs": [],
      "source": [
        "custom_quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
        "\n",
        "for column in ['age', 'blood_pressure_systolic', 'cholesterol']:\n",
        "    print(f\"\\n{column}:\")\n",
        "    for q in custom_quantiles:\n",
        "        value = healthcare_df[column].quantile(q)\n",
        "        print(f\"  {int(q*100)}th percentile: {value:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Lrqz1T4nLn"
      },
      "source": [
        "**Data distribution histogram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPozjvZO3OWW"
      },
      "outputs": [],
      "source": [
        "# Set up the plotting style\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# Create histograms for fintech data\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Fintech Dataset - Distribution Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Account Balance\n",
        "axes[0, 0].hist(fintech_df['account_balance'], bins=20, color='skyblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_title('Account Balance Distribution')\n",
        "axes[0, 0].set_xlabel('Account Balance ($)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "# matplotlib.use('Agg')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSXVSrjr3ngl"
      },
      "source": [
        "**Enhanced Histograms with Statistical Lines**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km1v9pyx3oof"
      },
      "outputs": [],
      "source": [
        "def create_enhanced_histogram(data, column, title, color='blue'):\n",
        "    \"\"\"Create histogram with statistical reference lines\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Create histogram\n",
        "    plt.hist(data[column], bins=20, color=color, alpha=0.7, edgecolor='black')\n",
        "\n",
        "    # Calculate statistics\n",
        "    mean_val = data[column].mean()\n",
        "    median_val = data[column].median()\n",
        "    q1 = data[column].quantile(0.25)\n",
        "    q3 = data[column].quantile(0.75)\n",
        "\n",
        "    # Add vertical lines for statistics\n",
        "    plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
        "    plt.axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
        "    plt.axvline(q1, color='orange', linestyle=':', linewidth=2, label=f'Q1: {q1:.2f}')\n",
        "    plt.axvline(q3, color='orange', linestyle=':', linewidth=2, label=f'Q3: {q3:.2f}')\n",
        "\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(column.replace('_', ' ').title())\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # Create enhanced histograms\n",
        "create_enhanced_histogram(fintech_df, 'account_balance', 'Account Balance Distribution with Statistics', 'skyblue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z2SauBp7nse"
      },
      "source": [
        "**Statistical** **summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6h1Sa_v7q4p"
      },
      "outputs": [],
      "source": [
        "def detailed_statistics(df, column):\n",
        "    \"\"\"Generate detailed statistics for a column\"\"\"\n",
        "    stats = {\n",
        "        'Count': df[column].count(),\n",
        "        'Mean': df[column].mean(),\n",
        "        'Median': df[column].median(),\n",
        "        'Mode': df[column].mode().iloc[0] if len(df[column].mode()) > 0 else 'No mode',\n",
        "        'Standard Deviation': df[column].std(),\n",
        "        'Variance': df[column].var(),\n",
        "        'Minimum': df[column].min(),\n",
        "        'Maximum': df[column].max(),\n",
        "        'Range': df[column].max() - df[column].min(),\n",
        "        'Q1 (25th percentile)': df[column].quantile(0.25),\n",
        "        'Q3 (75th percentile)': df[column].quantile(0.75),\n",
        "        'IQR': df[column].quantile(0.75) - df[column].quantile(0.25),\n",
        "        'Skewness': df[column].skew(),\n",
        "        'Kurtosis': df[column].kurtosis()\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "# Apply to key columns\n",
        "print(\"\\n=== DETAILED STATISTICS ===\")\n",
        "print(\"\\nAccount Balance (Fintech):\")\n",
        "balance_stats = detailed_statistics(fintech_df, 'account_balance')\n",
        "for stat, value in balance_stats.items():\n",
        "    if isinstance(value, (int, float)):\n",
        "        print(f\"{stat}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{stat}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqYSlvcA97i0"
      },
      "source": [
        "**Data** **Quality** **Assessment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6R4D94v-Cyt"
      },
      "outputs": [],
      "source": [
        "def assess_data_quality(df, dataset_name):\n",
        "    print(f\"\\n{dataset_name} Data Quality Report:\")\n",
        "    print(f\"Total rows: {len(df)}\")\n",
        "    print(f\"Total columns: {len(df.columns)}\")\n",
        "\n",
        "    # Missing values\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(f\"Missing values per column:\")\n",
        "    for col, missing in missing_values.items():\n",
        "        print(f\"  {col}: {missing} ({missing/len(df)*100:.1f}%)\")\n",
        "\n",
        "    # Outliers using IQR method\n",
        "    print(f\"\\nPotential outliers (using IQR method):\")\n",
        "    for col in df.select_dtypes(include=[np.number]).columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "        print(f\"  {col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n",
        "\n",
        "assess_data_quality(fintech_df, \"FINTECH\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
