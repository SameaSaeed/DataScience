{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import logging\n",
        "from pyspark.sql.functions import col, sum as _sum, when, row_number\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "E8xBrmROUAej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"VideoStreamingETL\").getOrCreate()\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "logging.getLogger(\"py4j\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "QwAq0PllT9BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract**"
      ],
      "metadata": {
        "id": "EJT_Tx-cUsCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_views = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(viewing_history_path)\n",
        "df_users = spark.read.option(\"multiline\", \"true\").json(users_path)\n",
        "df_videos_catalog = spark.read.parquet(videos_catalog_path)\n",
        "bucketed_df = spark.read.table(\"viewing_history_bucketed\")\n",
        "\n",
        "\"\"\" Extract Incremental Updates\"\"\"\n",
        "df_sub_updates= spark.read.option(\"header\", True).csv(subscription_updates_path)\n",
        "df_latest_updates = subscription_updates_df.filter(col(\"change_date\") >= \"2024-02-07\")"
      ],
      "metadata": {
        "id": "m_gMXEDTUtNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transform**"
      ],
      "metadata": {
        "id": "dn8xhVRcaABs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "yLrHGCaqUMAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered=df.select(\"col1\", \"col2\").show(5)\n",
        "null_count=df.select([_sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c .in df.columns])\n",
        "total_users=df.count()\n",
        "unique_users=df.select(\"user_id\").distinct().count()"
      ],
      "metadata": {
        "id": "-OWy_2iypGxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning"
      ],
      "metadata": {
        "id": "UHW61mz9pB4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"col_name\")\n",
        "df=df.dropna(subset=[\"col1\", \"col2\"])\n",
        "df=df.dropDuplicates([\"col1\"])\n",
        "df.fillna({\"col_name\": \"Unknown\"})\n",
        "df.withColumn(\"col_name\", col(\"col_name\").cast(int))\n",
        "df.withColumn(\"col_name\", to_timestamp(col(\"col_name\")))"
      ],
      "metadata": {
        "id": "QHHYImeNpAi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joining 2 data sources"
      ],
      "metadata": {
        "id": "4i09psFzspbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_full=df1.join(d2, on=\"col_name\", how=\"inner\")"
      ],
      "metadata": {
        "id": "QJ9PySJnstvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Window"
      ],
      "metadata": {
        "id": "6imzwm5i94xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_most_watched= df_full.groupBy(\"user_id\", \"video_id\").agg(count(\"*\").alias(\"watch_count\"))\n",
        "total_views_df= df_full.groupBy(\"user_id\").agg(count(\"*\").alias(\"total_views\")\n",
        "total_views_df.orderBy(\"total_views\",ascending=False).show(5)"
      ],
      "metadata": {
        "id": "pGnFmuFA95O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec=Window.partitionBy(\"user_id\").orderBy(\"watch_count\").desc())\n",
        "df_ranked=df_most_watched.withColumn(\"rank\",row_number().over(window_spec))\n",
        "df_top_videos_per_user=df_ranked.filter(col(\"rank\")<=3)\n",
        "df_top_videos_per_user.orderBy(\"user_id\", \"rank\").show(5)"
      ],
      "metadata": {
        "id": "5RMO1ZwkBlG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UDF"
      ],
      "metadata": {
        "id": "SQoXW9G9UZKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_device(device):\n",
        "  if device is None:\n",
        "    return \"Unknown\"\n",
        "  device= device.lower()\n",
        "  if device in iphone:\n",
        "    return \"iPhone\"\n",
        "  else:\n",
        "    return \"Other\"\n",
        "\n",
        "normalize_device_udf=udf(normalize_device, StringType())\n",
        "df=df.withColumn(\"normalized_device\",normalize_device_udf(df[\"device_type\"]))"
      ],
      "metadata": {
        "id": "55Kk2UXpRvFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load**"
      ],
      "metadata": {
        "id": "FejW1jjfaYVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partitioning reduces query scan time by storing data in separate folders."
      ],
      "metadata": {
        "id": "CbhlF8XJV-MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write to disk\n",
        "df.write.partitionBy(\"device_type\").mode(\"overwrite\").parquet(f\"{processed_path}/viewing_history_partitioned\")\n",
        "\n",
        "import os\n",
        "partitioned_path = f\"{processed_path}/viewing_history_partitioned\"\n",
        "print(\"Partitions created:\", os.listdir(partitioned_path))\n",
        "df_partitioned = spark.read.parquet(partitioned_path)\n",
        "df_partitioned.select(\"device_type\").distinct().show()"
      ],
      "metadata": {
        "id": "88eyZX9DV--h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bucketing improves performance for filtering and joins on bucketed columns."
      ],
      "metadata": {
        "id": "7nnUhsVRYEC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.bucketBy(10, \"video_id\")\n",
        ".sortBy(\"video_id\")\n",
        ".mode(\"overwrite\")\n",
        ".format(\"parquet\")\n",
        ".option(\"path\", f\"{processed_path}/viewing_history_bucketed\")\n",
        ".saveAsTable(\"viewing_history_bucketed\")\n",
        ")\n",
        "\n",
        "# Check if the table exists\n",
        "spark.catalog.listTables()\n",
        "# Verify bucketing in table schema\n",
        "spark.sql(\"DESCRIBE FORMATTED viewing_history_bucketed\").show()"
      ],
      "metadata": {
        "id": "58m0ounVYHuj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}